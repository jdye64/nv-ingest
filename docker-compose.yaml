# SPDX-FileCopyrightText: Copyright (c) 2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: LicenseRef-NvidiaProprietary
#
# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual
# property and proprietary rights in and to this material, related
# documentation and any modifications thereto. Any use, reproduction,
# disclosure or distribution of this material and related documentation
# without an express license agreement from NVIDIA CORPORATION or
# its affiliates is strictly prohibited.

services:
  redis:
    image: "redis/redis-stack"
    ports:
      - "6379:6379"

  tika:
    image: apache/tika:latest
    ports:
      - "9998:9998"

  yolox:
    # NeMo ON
    image: "nvcr.io/nvstaging/nim/nv-yolox:24.07-17583450"
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=$NIM_NGC_API_KEY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

    # NeMo OFF
    # image: "nvcr.io/nvidia/tritonserver:24.06-py3"
    # command: bash -c "tritonserver --model-repository=/models --exit-on-error=false --model-control-mode=explicit --load-model yolox"
    # ports:
    #   - "8000:8000"
    #   - "8001:8001"
    #   - "8002:8002"
    # volumes:
    #   - ${NV_INGEST_ROOT}/models/yolox:/models/yolox
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # runtime: nvidia

  deplot:
    # NeMo ON
    image: "gitlab-master.nvidia.com:5005/nim/nim-factory/google-deplot:24.07-17654435"
    ports:
      - "8003:8000"
      - "8004:8001"
      - "8005:8002"
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=$NIM_NGC_API_KEY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

    # NeMo OFF
    # image: nvcr.io/nvidian/nemo-llm/nemo-retriever-triton:0.0.4
    # shm_size: 2gb
    # command: bash -c "tritonserver --model-repository=/models --exit-on-error=false --model-control-mode=explicit --load-model deplot"
    # ports:
    #   - "8003:8000"
    #   - "8004:8001"
    #   - "8005:8002"
    # volumes:
    #   - ${NV_INGEST_ROOT}/models/deplot:/models/deplot
    # privileged: true
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # runtime: nvidia

  cached:
    # NeMo ON
    image: nvcr.io/nvstaging/nim/cached:24.07-17586292
    shm_size: 2gb
    ports:
      - "8006:8000"
      - "8007:8001"
      - "8008:8002"
    privileged: true
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=$NIM_NGC_API_KEY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

    # NeMo OFF
    # image: nvcr.io/nvstaging/nim/cached:24.07-17586292
    # shm_size: 2gb
    # command: bash -c "tritonserver --model-repository=/models --exit-on-error=false --model-control-mode=explicit --load-model cached"
    # ports:
    #   - "8006:8000"
    #   - "8007:8001"
    #   - "8008:8002"
    # volumes:
    #   - ${NV_INGEST_ROOT}/models/cached:/models/cached
    # privileged: true
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # runtime: nvidia

  paddle:
    # NeMo ON
    image: nvcr.io/nvstaging/nim/paddleocr:24.07-17586069
    shm_size: 2gb
    ports:
      - "8009:8000"
      - "8010:8001"
      - "8011:8002"
    privileged: true
    environment:
      - NIM_HTTP_API_PORT=8000
      - NIM_TRITON_LOG_VERBOSE=1
      - NGC_API_KEY=$NIM_NGC_API_KEY
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia

    # NeMo OFF
    # image: nvcr.io/nvidian/nemo-llm/nemo-retriever-triton-mmdet:0.0.1
    # shm_size: 2gb
    # command: bash -c "tritonserver --model-repository=/models --exit-on-error=false --model-control-mode=explicit --load-model paddle"
    # ports:
    #   - "8009:8000"
    #   - "8010:8001"
    #   - "8011:8002"
    # volumes:
    #   - ${NV_INGEST_ROOT}/models/paddle:/models/paddle
    # privileged: true
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # runtime: nvidia

  nv-ingest-ms-runtime:
    image: "nv-ingest:latest"
    build:
      context: ${NV_INGEST_ROOT}
      dockerfile: "./Dockerfile"
      target: runtime
    volumes:
      - ${DATASET_ROOT}:/workspace/data
    cap_add:
      - sys_nice
    environment:
      - MESSAGE_CLIENT_HOST=redis
      - MESSAGE_CLIENT_PORT=6379
      - REDIS_MORPHEUS_TASK_QUEUE=morpheus_task_queue
      - ECLAIR_GRPC_TRITON=triton-eclair:8001
      - OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
      - INGEST_LOG_LEVEL=INFO
      - CAPTION_CLASSIFIER_GRPC_TRITON=yolox:8001
      - TABLE_DETECTION_GRPC_TRITON=yolox:8001
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  nv-ingest-ms-dev:
    image: "nv-ingest-ms-dev:24.03"
    build:
      context: ${NV_INGEST_ROOT}
      dockerfile: "./Dockerfile"
      target: development
    volumes:
      - ${DATASET_ROOT}:/workspace/data
      - ${NV_INGEST_ROOT}/src:/workspace/src
    stdin_open: true
    tty: true
    cap_add:
      - sys_nice
    environment:
      - MESSAGE_CLIENT_HOST=redis
      - MESSAGE_CLIENT_PORT=6379
      - REDIS_MORPHEUS_TASK_QUEUE=morpheus_task_queue
      - ECLAIR_TRITON_HOST=triton
      - ECLAIR_TRITON_PORT=8001
      - OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.91.0
    hostname: otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./config/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "8888:8888" # Prometheus metrics exposed by the collector
      - "8889:8889" # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "9411" # Zipkin receiver
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP/HTTP receiver
      - "55680:55679" # zpages extension
    depends_on:
      - zipkin

  zipkin:
    image: openzipkin/zipkin
    environment:
      JAVA_OPTS: "-Xms2g -Xmx2g -XX:+ExitOnOutOfMemoryError"
    ports:
      - "9411:9411" # Zipkin UI and API

  prometheus:
    image: prom/prometheus:latest
    command:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=1h
      - --config.file=/etc/prometheus/prometheus-config.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --enable-feature=exemplar-storage
      - --enable-feature=otlp-write-receiver
    volumes:
      - ./config/prometheus.yaml:/etc/prometheus/prometheus-config.yaml
    ports:
      - "9090:9090"

  grafana:
    container_name: grafana-service
    image: grafana/grafana
    ports:
      - "3000:3000"
