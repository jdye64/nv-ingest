# SPDX-FileCopyrightText: Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES.
# All rights reserved.
# SPDX-License-Identifier: Apache-2.0

services:
  redis:
    image: "redis/redis-stack"
    ports:
      - "6379:6379"

  nv-ingest-ms-runtime:
    # image: nvcr.io/ohlfw0olaadg/ea-participants/nv-ingest:24.10.1
    build:
      context: ${NV_INGEST_ROOT:-.}
      dockerfile: "./Dockerfile"
      target: development
    volumes:
      - ${NV_INGEST_ROOT}:/workspace/nv_ingest_dev
    environment:
      # Self-hosted cached endpoints.
      - CACHED_GRPC_ENDPOINT=cached:8001
      - CACHED_HTTP_ENDPOINT=http://cached:8000/v1/infer
      - CACHED_INFER_PROTOCOL=grpc
      # build.nvidia.com hosted cached endpoints.
      #- CACHED_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/university-at-buffalo/cached
      #- CACHED_INFER_PROTOCOL=http
      - CUDA_VISIBLE_DEVICES=0
      #- DEPLOT_GRPC_ENDPOINT=""
      # Self-hosted deplot endpoints.
      - DEPLOT_HTTP_ENDPOINT=http://deplot:8000/v1/chat/completions
      # build.nvidia.com hosted deplot
      #- DEPLOT_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/vlm/google/deplot
      - DEPLOT_INFER_PROTOCOL=http
      - DOUGHNUT_GRPC_TRITON=triton-doughnut:8001
      - INGEST_LOG_LEVEL=DEFAULT
      # Message client for development
      #- MESSAGE_CLIENT_HOST=0.0.0.0
      #- MESSAGE_CLIENT_PORT=7671
      #- MESSAGE_CLIENT_TYPE=simple # Configure the ingest service to use the simple broker
      # Message client for production
      - MESSAGE_CLIENT_HOST=redis
      - MESSAGE_CLIENT_PORT=6379
      - MESSAGE_CLIENT_TYPE=redis
      - MINIO_BUCKET=${MINIO_BUCKET:-nv-ingest}
      - MRC_IGNORE_NUMA_CHECK=1
      - NGC_API_KEY=${NGC_API_KEY:-ngcapikey}
      - NVIDIA_BUILD_API_KEY=${NVIDIA_BUILD_API_KEY:-${NGC_API_KEY:-ngcapikey}}
      - OTEL_EXPORTER_OTLP_ENDPOINT=otel-collector:4317
      # Self-hosted paddle endpoints.
      - PADDLE_GRPC_ENDPOINT=paddle:8001
      - PADDLE_HTTP_ENDPOINT=http://paddle:8000/v1/infer
      - PADDLE_INFER_PROTOCOL=grpc
      # build.nvidia.com hosted paddle endpoints.
      #- PADDLE_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/baidu/paddleocr
      #- PADDLE_INFER_PROTOCOL=http
      - READY_CHECK_ALL_COMPONENTS=True
      - REDIS_MORPHEUS_TASK_QUEUE=morpheus_task_queue
      # Self-hosted redis endpoints.
      - YOLOX_GRPC_ENDPOINT=yolox:8001
      - YOLOX_HTTP_ENDPOINT=http://yolox:8000/v1/infer
      - YOLOX_INFER_PROTOCOL=grpc
      # build.nvidia.com hosted yolox endpoints.
      #- YOLOX_HTTP_ENDPOINT=https://ai.api.nvidia.com/v1/cv/nvidia/nv-yolox-page-elements-v1
      #- YOLOX_INFER_PROTOCOL=http
      - VLM_CAPTION_ENDPOINT=https://ai.api.nvidia.com/v1/gr/meta/llama-3.2-90b-vision-instruct/chat/completions
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["1"]
              capabilities: [gpu]
